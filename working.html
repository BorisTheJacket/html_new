<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Boris resume</title>
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <nav>
        <div class="box1"><a href="index.html">Resume</a> </div>
        <div class="position">
            
            <div class="box3"><a href="working.html">Projects in progress</a> </div>
            <div class="box2"><a href="future.html">Future projects</a> </div>

        </div>
    </nav>
    <div class="container">
        <!-- <div class="info">
            <div class="info-text">
                <h1>Here's my working projects</h1>
            </div>
        </div> -->

            <div class="card bg-yellow">
                <!-- <li> -->
                    <h3 class="card_title"><a href="https://github.com/BorisTheJacket/parser" target="_blank">Html parser</a></h3>
                    <h4>This parser I'm using on my current position. I decided to work smarter not harder, that's why this parser exists.</h4>
                    <h4 class="list_title">How the parser works:</h4>
                    <ul>
                        <li>It gathers html code from website;</li>
                    
                            <!-- <pre>
                                <code>
<p>from bs4 import BeautifulSoup
import requests
import os
from pars_number import list_of_values



BASE_DIR = "F:/python/ПАРСЕР_САНТЕХ/"

headers = { # Это что-то вроде маски под которой мой комп заходит на сайты, чтобы его не забанили, т.к. без него может быть такая возможность
    "Accept":"*/*",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"
    } 



if __name__ == '__main__':
    
    folder_for_all_documents = os.path.join(BASE_DIR, 'folder')
    os.mkdir(folder_for_all_documents)

    for item in list_of_values:  
        
        # Через поиск находим нужный нам адрес и пихаем его в get_to_product

        server = "https://www.santech.ru"
        resp = requests.get("https://www.santech.ru/catalog/autocomplete/?term=%s" % item) # Тут получаю через поисковую строку адрес нужного мне товара
        soup = BeautifulSoup(resp.text, "lxml")
        
        #  Проверяем есть ли ссылка, т.к. может быть такое что товар есть в моём списке, но его нет на нужном сайте
        alert_block = soup.find(class_="ss-p-10")
        if alert_block is not None:
            continue

        # Тут забираю нужную мне ссылку и присваиваю её get_to_product
        product_url = soup.find(class_="ss-search-item").find("a")
        get_to_product = product_url["href"]

        # Заходим на страницу с нужными данными
        req = requests.get(server + get_to_product, headers=headers) 
        # Забираем это как текст
        new_site = BeautifulSoup(req.text, "lxml") 

        #  Здесь запишем название Товара
        title = new_site.find(class_="product__title")


        # Здесь запишем нужные нам страницы в html файлы, чтобы больше не посылать запросы к сайту
        with open(f"{folder_for_all_documents}/{item}.html", "w", encoding="utf-8") as file:
            file.write(req.text)</p>
                                </code>
                            </pre> -->
                    
                    
                        <li>Collects necessary data from html code;</li>
                    
                    <!-- <pre>
                        <code>
                            <p>from bs4 import BeautifulSoup
import json
import os
from pandas import DataFrame


variable_dict = {} # Здесь будет словарь со значениями внутри цикла
pod_zakaz = [] # Список словарей, нужен чтобы работать с dataframe, так как он таким образом засовывает в эксельку
list_of_dict = []

headers = { # Это что-то вроде маски под которой мой комп заходит на сайты, чтобы его не забанили, т.к. без него может быть такая возможность
"Accept":"*/*",
"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"
} 

if __name__ == '__main__':


for item in os.listdir("F:/python/ПАРСЕР_САНТЕХ/folder/"): # Захожу папку с хтмлками

file_path = f'F:/python/ПАРСЕР_САНТЕХ/folder/{item}'
    
with open(file_path, encoding="utf-8") as f:
    new_site = BeautifulSoup(f, "html.parser") 
    # Тут вызываю бютифул суп чтобы мочь парсить
    
    new_table_name = []
    table_value = []
    
    title = new_site.find(class_="product__title").text.strip() 
    # Тут Забираю название Товара

    if new_site.find(class_='territory-choose__list-count').text.strip() == "под заказ":
        
        for element in new_site.find_all(class_="property__table-tr"):
            if element.find(class_="property__table-name") is not None:
                if element.find(class_="title") is not None:
                    new_table_name.append(element.find(class_="title").text.strip())
                else:
                    new_table_name.append(element.find(class_="property__table-name").text.strip())
                table_value.append(element.find(class_="property__table-value").text.strip())
                
            elif element.find(class_="title") is not None:
                new_table_name.append(element.find(class_="title").text.strip())
                table_value.append(element.find(class_="property__table-value").text.strip())
                
            else:
                new_table_name.append(element.find(class_="property__table-name item-specs-col").text.strip())
                table_value.append(element.find(class_="property__table-value item-specs-col").text.strip())
                

    # Тут забираю все значения из таблицы

    
        variable_dict = {new_table_name[i]: table_value[i] for i in range(0, len(new_table_name))} # Делаю словарь из двух списков
        variable_dict['Название'] = title # Добавляю в словарь название Товара
        
        pod_zakaz.append(variable_dict) # Добавляю словарь в список, чтобы мочь его вывести в эксельку
    else:
        for element in new_site.find_all(class_="property__table-tr"):
            if element.find(class_="property__table-name") is not None:
                if element.find(class_="title") is not None:
                    new_table_name.append(element.find(class_="title").text.strip())
                else:
                    new_table_name.append(element.find(class_="property__table-name").text.strip())
                table_value.append(element.find(class_="property__table-value").text.strip())
                
            elif element.find(class_="title") is not None:
                new_table_name.append(element.find(class_="title").text.strip())
                table_value.append(element.find(class_="property__table-value").text.strip())
                
            else:
                new_table_name.append(element.find(class_="property__table-name item-specs-col").text.strip())
                table_value.append(element.find(class_="property__table-value item-specs-col").text.strip())
                

        # Тут забираю все значения из таблицы

    
        variable_dict = {new_table_name[i]: table_value[i] for i in range(0, len(new_table_name))} # Делаю словарь из двух списков
        variable_dict['Название'] = title # Добавляю в словарь название Товара
        
        list_of_dict.append(variable_dict) # Добавляю словарь в список, чтобы мочь его вывести в эксельку

    

with open(f"{' '.join(pod_zakaz[0]['Название'].split()[:3])} под заказ.json", "w", encoding="utf-8") as f:
json.dump(pod_zakaz, f, ensure_ascii=False, indent=4)


df = DataFrame(sorted(pod_zakaz, key=len)) # Собственно выхываю датафрейм к этому списку и засовываю его в эксельку
df.to_excel(f"{' '.join(pod_zakaz[0]['Название'].split()[:3])} под заказ.xlsx", sheet_name="sheet2", index=False)

with open(f"{' '.join(list_of_dict[0]['Название'].split()[:3])} в наличии.json", "w", encoding="utf-8") as f:
json.dump(list_of_dict, f, ensure_ascii=False, indent=4)


df = DataFrame(sorted(list_of_dict, key=len)) # Собственно выхываю датафрейм к этому списку и засовываю его в эксельку
df.to_excel(f"{' '.join(list_of_dict[0]['Название'].split()[:3])} в наличии.xlsx", sheet_name="sheet2", index=False)
                            </p>
                        </code>
                    </pre> -->
                    
                        <li>Presents Excel sheet with necessary data.</li>
                        <img src="excel_table_data_parser.png" alt="Here's have to excel-table" class="img_working"></img>
                    </ul>  
            </div>
            
            
            <div class="card bg-red-working">
                
                    <h3 class="card_title"><a href="https://github.com/BorisTheJacket/parser_amo_crm" target="_blank">AMO CRM parser for reports</a></h3>
                    <h4>I developed parser for my friend, who didn't want to do annoying job. In the link on GitHub you can find good writed technical documentation.</h4>
                    <h4 class="list_title">How the parser works:</h4>
                    <ul>
                        <li>By API-key it logs in the AMO CRM account;</li>
                        <li>It takes an e-mail from message via TG-bot;</li>
                        <img src="amo_crm_parser_1.png" alt="Image of TG-bot">
                        <li style="margin-top: 10px;"> Findes lead profile with e-mail;</li>
                        <li>Takes all information from lead profile;</li>
                        <li>Send the report by TG-bot;</li>
                        <img src="amo_crm_parser_2.png" alt="Image of TG-bot">
                        <li style="margin-top: 10px;">Example of report:</li>
                        <img src="amo_crm_parser_3.png" alt="Image of TG-bot">
                    </ul>    
            </div>
            
            
            <div class="card bg-green-working">
                <li class="card_li">
                    <h3 class="card_title">Examples of my current html layout</h3>
                    <ul>
                        <li><a href="https://dn.ru/radiator/aliuminievyi/nrz/optima_500_100"><img src="dn_1.png" alt="DN image 1"></a> </li>
                        <li><a href="https://dn.ru/kompensator/rezinovyi/flantcevyi/dn/nbr-pn10"><img src="dn_2.png" alt="DN image 2"></a> </li>
                    </ul>

                </li>
            </div> 

    </div>
    

</body>

</html>
